---
layout: home
title: Dr. Xingjun Ma
subtitle: Associate Professor, Fudan University
---

<p style="text-align:center;">
	<img src="/assets/img/xxx.png" alt="mind and universe in Atlantean language" width="720" height="60">
</p>

<p style="text-align:justify">
I am an associate professor of computer science at Fudan University and a member of <a href="https://fvl.fudan.edu.cn/" target="_blank"> Fudan Vision and Learning Lab</a>. I am also an honorary fellow at The University of Melbourne. My main research area is <b>Trustworthy AI</b>, aiming to develop <b>secure</b>, <b>robust</b>, <b>explainable</b>, <b>privacy-preserving</b>, and <b>fair</b> learning algorithms and AI models for different applications. I am also passionate about using AI to expand understandings of our mind and the universe. </p>


<p style="text-align:justify">
I received my Ph.D. degree from The University of Melbourne and spent another 2 wonderful years as a postdoctoral research fellow. I worked for 1.5 years at Deakin University as a lecturer before joining Fudan University. I obtained my bachelor's and master's degrees from Jilin University and Tsinghua University, respectively.
</p>

<!-- <p style="text-align:justify">
I received my Ph.D. degree from The University of Melbourne supervised by Prof. <a href="https://people.eng.unimelb.edu.au/baileyj/" target="_blank">James Bailey</a> and Dr. <a href="https://scholar.google.com/citations?user=MjgOHPYAAAAJ&hl=en" target="_blank">Sudanthi Wijewickrema</a>. Prior to Fudan, I spent ~2 years at The University of Melbourne as a research fellow and 1.5 years at Deakin University as a lecturer. I obtained my bachelor's and master's degrees from Jilin University and Tsinghua University, respectively.
</p> -->

<div align="center">
	<figure style="width: 80%">
	        <p>"Everything should be as simple as possible, but not simpler."</p>
	    <!-- <figcaption align="right">—<i>Albert Einstein</i></figcaption> -->
	</figure>
</div>

<p style="text-align:center">
	<a href="mailto:xingjunma@fudan.edu.cn" target="_blank">Email</a> &nbsp;/&nbsp;
    <a href="https://scholar.google.com.au/citations?user=XQViiyYAAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
    <a href="https://github.com/xingjunm/" target="_blank">Github</a>
</p>

<!-- <p><font color="red"><strong>For master/hornors students, contact me if you are interested in doing machine learning research with me.</strong></font>
</p> -->

<hr>

<p style="text-align:center">
	<font color="#0000FF">
		We are looking for motivated students, postdocs, and interns in the field of Trustworthy AI, Multimodal Learning, Reinforcement Learning, and Generative AI to join our team. Drop me an email if you are interested.
	<!-- </br> -->
		<!-- 团队招收可信ML和大语言模型方向的研究生、博士后和实习生，欢迎感兴趣的同学联系.  -->
	</font> 
</p>

<p style="text-align:center">
	I am teaching a graduate level course <a href="https://trust-ml.github.io/" target="_blank">Trustworthy Machine Learning</a> and an introductory course <a href="https://highschool.opentai.org/" target="_blank">Artificial Intelligence</a> dedicated for high school students. </br>

	We are also writing an AI Security book <a href="https://books.opentai.org/" target="_blank"><i>Artificial Intelligence - Data and Model Security</i></a> in Chinese. Feel free to contact us to fix the errors and mistakes should you find any.
</p>

<hr>

<h3>Latest News</h3>

<ul> 
	<li><strong>[04/2024]</strong> Our work on reinforcement learning is accepted by IJCAI'24. </li>

	<li><strong>[03/2024]</strong> Our work on <a href="https://arxiv.org/abs/2305.02605" target="_blank"> adversarial robustness of reinforcement learning </a> is accepted by DSN'24. </li>

	<li><strong>[03/2024]</strong> Our work on <a href="https://arxiv.org/abs/2311.05915" target="_blank"> safety alignment of LLMs </a> is accepted by NAACL'24. </li>

	<li><strong>[03/2024]</strong> Our work on <a href="https://arxiv.org/abs/2205.12709" target="_blank"> machine unlearning </a> is accepted by TDSC. </li>

	<li><strong>[01/2024]</strong> Our new regularization method <a href="https://openreview.net/pdf?id=oZyAqjAjJW" target="_blank"> LDReg </a> for self-supervised learning is accepted by ICLR'24. </li>

	<!-- <li><strong>[4/2023]</strong> Our work on <a href="https://arxiv.org/abs/2305.14876" target="_blank"> backdoor defense </a> is accepted by ICML'23. </li>

	<li><strong>[3/2023]</strong> Our work on <a href="https://arxiv.org/abs/2006.13726" target="_blank"> margin decomposition adversarial attack </a> is accepted by Machine Learning journal. </li>

	<li><strong>[2/2023]</strong> Our work on <a href="https://arxiv.org/abs/2301.01217" target="_blank"> unlearnable examples </a> is accepted by CVPR'23. </li>

	<li><strong>[1/2023]</strong> Our work <a href="https://link.springer.com/article/10.1007/s10853-022-07793-6" target="_blank">Machine learning guided alloy design of high-temperature NiTiHf shape memory alloys</a> recieves the <a href="https://link.springer.com/article/10.1007/s10853-023-08250-8#:~:text=The%20winner%20of%20the%202022,Corujeira%20Gallo%2C%20and%20Wei%20Xu." target="_blank" style = "color: red">2022 Robert W. Cahn Best Paper Award</a> at Journal of Materials Science. Congrats to all the authors!</li>

	<li><strong>[1/2023]</strong> Our works on <a href="https://arxiv.org/abs/2301.10908" target="_blank"> Cognitive Backdoor Distillation </a> and <a href="https://openreview.net/forum?id=-htnolWDLvP" target="_blank"> Transferable Unlearnable Examples </a>  are accepted by ICLR'23. </li>

	<li><strong>[1/1/2023]</strong> Merry christmas and happy new year! -->

	<!-- <li><strong>[11/2022]</strong> Our work on <a href="https://arxiv.org/abs/2211.07915" target="_blank"> Time Series Backdoor Attacks </a> is accepted by <a href="https://satml.org/" target="_blank"> SaTML 2023 </a></li>

	<li><strong>[10/2022]</strong> Our survey paper on <a href="https://arxiv.org/abs/2012.06337" target="_blank"> Privacy and Robustness of Federeatd Learning </a> is accepted by TNNLS</li>

	<li><strong>[10/2022]</strong> Our work on <a href="https://arxiv.org/abs/2210.09545" target="_blank"> Backdoor Defense of Fine-tuned Language Models </a> is accepted by EMNLP'22</li>

	<li><strong>[09/2022]</strong> Our theoretical work on <a href="https://www.mdpi.com/1099-4300/24/9/1220" target="_blank"> Local Intrinsic Dimensionality, Entropy and Statistical Divergences </a> is accepted by Entropy. </li>

	<li><strong>[09/2022]</strong> Our work on <a href="https://arxiv.org/abs/2205.14926" target="_blank"> Federated Adversarial Training </a> is accepted by NeurIPS'22. </li>

	<li><strong>[08/2022]</strong> Our work <a href="https://arxiv.org/abs/2207.05641" target="_blank"> Backdoor Attack on Crowd Counting </a> is accepted by ACMMM’22. </li>

	<li><strong>[01/2022]</strong> Our work on <a href="https://openreview.net/pdf?id=qSV5CuSaK_a" target="_blank"> Visual Object Tracking (VOT) Backdoor</a> is accepted by ICLR'22. </li>

	<li><strong>[12/2021]</strong> Our work on <a href="https://arxiv.org/abs/2112.05588" target="_blank">Copyright Protection of Deep Learning Models</a> is accepted by IEEE S&P'22. </li>

	<li><strong>[10/2021]</strong> Our work <a href="https://www.sisap.org/2021/awards.html" target="_blank">Relationships between Local Intrinsic Dimensionality and Tail Entropy</a> recieves the <strong><font color="red">Best Paper Award</font></strong> at SISAP'21.</li>

	<li><strong>[09/2021]</strong> Our works on <a href="https://arxiv.org/abs/2110.11571" target="_blank">Anti-Backdoor Learning</a>, <a href="https://arxiv.org/abs/2110.03825" target="_blank">Robust Neural Architecture</a>, <a href="http://arxiv.org/abs/2110.13675" target="_blank">Alpha-IoU Loss</a> and <a href="" target="_blank">Fairness in Collabarative Learning</a> are accepted by NeurIPS'21. </li>

	<li><strong>[08/2021]</strong> I will serve as a SPC Member for AAAI'22. </li>
	
	<li><strong>[07/2021]</strong> Our work on <a href="https://arxiv.org/abs/2108.07969" target="_blank">Adversarial Robustness Distillation</a> is accepted by ICCV'21. </li>

	<li><strong>[07/2021]</strong> Our work  <a href="https://ssdbm.org/2021/awards" target="_blank">Sub-trajectory Similarity Join with Obfuscation</a> recieves the <strong><font color="red">Best Paper Runner-up Award</font></strong> at SSDBM'21, congrats to all the authors.</li>
	
	<li><strong>[06/2021]</strong> Our work  <a href="https://hanxunh.github.io/Unlearnable-Examples/" target="_blank">Unlearnable Examples: Making Personal Data Unexploitable</a> is featured by <a href="https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview" target="_blank">MIT Technology Review</a> and <a href="https://pursuit.unimelb.edu.au/articles/blocking-ai-to-keep-your-personal-data-your-own" target="_blank">PURSUIT</a>.</li>

	<li><strong>[05/2021]</strong> I am recognized as an <a href="https://iclr.cc/Conferences/2021/Reviewers"  target="_blank">Outstanding Reviewer</a> for ICLR'21.</li>

	<li><strong>[04/2021]</strong> Our work on  <a href="https://arxiv.org/abs/2106.01532" target="_blank">Inpainting Detection</a> is accepted by IJCAI'21.</li>


	<li><strong>[02/2021]</strong> I received the Mini ARC Analog Programme (MAAP) - Discovery Grant from Deakin University as a Co-PI.</li>

	<li><strong>[01/2021]</strong> Our works on <a href="https://openreview.net/forum?id=iAmZUo0DxC0" target="_blank">Data Protection</a>, <a href="https://openreview.net/forum?id=zQTezqCCtNx" target="_blank">Adversarial Defense</a>  and <a href="https://openreview.net/forum?id=9l0K4OM-oXE" target="_blank">Backdoor Defense</a> are accepted by ICLR'21.</li> -->
 
</ul>

<hr>
<h3> Research Interests</h3>
<ul>
	<li> Trustworthy machine learning
		<ul>
			<li> Adversarial learning: adversarial/backdoor attack/defense </li>
			<li> Self-supervised learning </li>
			<li> Fairness and data privacy   </li>
			<li> Watermark and copyright protection </li>
		</ul>
	</li>
	<li> Generative AI and large models 
		<ul>
			<li> Ethics and values evaluation of large language models </li>
			<li> Large language model alignment (with human values) </li>
			<li> Diffuson models: mechanism, theory, and traceable application </li>
			<li> Vulnerabilities of large vision/language/multimodel models </li>
		</ul>
	</li>
</ul>

<hr>

<h3> Current PhD Students</h3>

<ul>
	<!-- <li> Yifeng Gao (Fudan University, 2023) </li>
	<li> Yifan Ding (Fudan University, 2023) </li>
	<li> Nuofan Wang (Fudan University, 2023) </li>
	<li> Ye Sun (Fudan University, 2023) </li>
	<li> Yixu Wang (Fudan University, 2023) </li>
	<li> Kun Zhai (Fudan University, 2022) </li>
	<li> Xin Wang (Fudan University, 2022) </li>
	<li> Teng Li (Fudan University, 2022) </li> -->
	<li> Xueqi Ma (University of Melbourne, 2022) </li>
	<li> Hanxun Huang (University of Melbourne, 2021) </li>
	<li> Yujing Jiang (University of Melbourne, 2020) </li>
	<!-- <li> Siqi Xia (Deakin) </li>
	<li> Chuxuan Tong (Deakin) </li>
	<li> Xinzhe Li (Deakin) </li>
	<li> Saheed Adebayo Tijani (Deakin) </li>
	<li> Zichan Ruan (Deakin) </li>
	<li> Gayathri Radhabai Gopinathan Nair (Deakin) </li> -->
</ul>

<hr>

<h3> Professional Activities</h3>

<ul>
	<li> <b>Program Committee Member</b>
		<ul>
			<li>ICLR (2019-2023), ICML (2019-2023), NeurIPS (2019-2023), CVPR (2020-2023), ICCV (2021-2023), ECCV (2020), AAAI (2020-2022), IJCAI (2020-2021), KDD (2019,2021), ICDM (2021), SDM (2021), AICAI (2021)</li>
			<!-- <li>ICML: 2019, 2020, 2021, 2022</li>
			<li>NeurIPS: 2019, 2020, 2021, 2022</li>
			<li>CVPR: 2020, 2021, 2022</li>
			<li>ICCV: 2021</li>
			<li>ECCV: 2020</li>
			<li>AAAI: 2020, 2021, 2022</li>
			<li>IJCAI: 2020, 2021</li>
			<li>KDD: 2019, 2021</li>
			<li>ICDM: 2021</li>
			<li>SDM: 2021</li>
			<li>AJCAI: 2021</li> -->
		</ul>
	</li>

	<li> <b>Journal Reviewer</b>
		<ul>
			<li>Nature Communications, Pattern Recognition, TPAMI, TIP, IJCV, JAIR, TNNLS, TKDE, TIFS, TOMM, KAIS</li>
			<!-- <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
			<li>IEEE Transactions on Image Processing (TIP)</li>
			<li>International Journal of Computer Vision (IJCV)</li>
			<li>Pattern Recognition</li>
			<li>Journal of Artificial Intelligence Research (JAIR)</li>
			<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
			<li>IEEE Transactions on Knowledge and Data Engineering (TKDE)</li>
			<li>Transactions on Information Forensics and Security (TIFS)</li>
			<li>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</li>
			<li>Knowledge and Information Systems (KAIS)</li>
			<li>Neurocomputing</li>
			<li>IEEE Robotics and Automation Letters (RA-L)</li>
			<li>Pattern Recognition Letters</li> -->
		</ul>
	</li>

</ul>

